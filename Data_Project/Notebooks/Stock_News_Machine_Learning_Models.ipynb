{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Process\n",
    "Data source: https://www.kaggle.com/aaron7sun/stocknews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Combined_News_DJIA.csv')\n",
    "# 8:2 split proportion\n",
    "train = data[data['Date'] < '2015-01-01']\n",
    "test = data[data['Date'] > '2014-12-31']\n",
    "trainheadlines = []\n",
    "for row in range(0, len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in train.iloc[row,2:27]))\n",
    "testheadlines = []\n",
    "for row in range(0, len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "\n",
    "# People are more likely to react to the bad news than to the good news\n",
    "# We set a high threshold, which means that the news should be good enough so that the DJIA will rise\n",
    "THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "(All the GridSearchCV are done on the Google Cloud Virtual Machine to get the optimal parameters of each model with the highest accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CountVectorizer(single word) + Logistic Regression(C = 0.1, solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"logisticregression__solver\": ['newton-cg', 'lbfgs', 'sag'],\n",
    "              \"countvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"countvectorizer__analyzer\": ['char', 'char_wb', 'word']\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(CountVectorizer(max_features = 200000), LogisticRegression(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, train['Label'])\n",
    "grid.best_params_\n",
    "\n",
    "# results:\n",
    "# {'countvectorizer__analyzer': 'char',\n",
    "#  'countvectorizer__ngram_range': (1, 1),\n",
    "#  'logisticregression__C': 0.1,\n",
    "#  'logisticregression__solver': 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = CountVectorizer(max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = LogisticRegression(C = 0.1, solver = 'lbfgs')\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19419</th>\n",
       "      <td>nigeria</td>\n",
       "      <td>0.290278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261</th>\n",
       "      <td>self</td>\n",
       "      <td>0.251950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>korea</td>\n",
       "      <td>0.245221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29286</th>\n",
       "      <td>tv</td>\n",
       "      <td>0.239821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26323</th>\n",
       "      <td>so</td>\n",
       "      <td>0.235939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Coefficient\n",
       "19419  nigeria     0.290278\n",
       "25261     self     0.251950\n",
       "15998    korea     0.245221\n",
       "29286       tv     0.239821\n",
       "26323       so     0.235939"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicwords = basicvectorizer.get_feature_names()\n",
    "basiccoeffs = basicmodel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16949</th>\n",
       "      <td>low</td>\n",
       "      <td>-0.259891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>country</td>\n",
       "      <td>-0.278557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25433</th>\n",
       "      <td>sex</td>\n",
       "      <td>-0.285887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24754</th>\n",
       "      <td>sanctions</td>\n",
       "      <td>-0.309829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24542</th>\n",
       "      <td>run</td>\n",
       "      <td>-0.341968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Coefficient\n",
       "16949        low    -0.259891\n",
       "7139     country    -0.278557\n",
       "25433        sex    -0.285887\n",
       "24754  sanctions    -0.309829\n",
       "24542        run    -0.341968"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TfidfVectorizer(two connected words) + Logistic Regression(solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              \"logisticregression__solver\": ['newton-cg', 'lbfgs', 'sag'],\n",
    "              \"tfidfvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"tfidfvectorizer__analyzer\": ['char', 'word']\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(TfidfVectorizer(max_features = 200000), LogisticRegression(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, train['Label'])\n",
    "grid.best_params_\n",
    "\n",
    "# results:\n",
    "# {'logisticregression__C': 1,\n",
    "#  'logisticregression__solver': 'newton-cg',\n",
    "#  'tfidfvectorizer__analyzer': 'word',\n",
    "#  'tfidfvectorizer__ngram_range': (2, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49206349206349204\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = TfidfVectorizer(ngram_range = (2,2), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = LogisticRegression(solver = 'newton-cg')\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>and other</td>\n",
       "      <td>0.423823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108497</th>\n",
       "      <td>right to</td>\n",
       "      <td>0.400289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121841</th>\n",
       "      <td>set to</td>\n",
       "      <td>0.343416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149475</th>\n",
       "      <td>the first</td>\n",
       "      <td>0.337250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151294</th>\n",
       "      <td>the pope</td>\n",
       "      <td>0.329685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Coefficient\n",
       "4932    and other     0.423823\n",
       "108497   right to     0.400289\n",
       "121841     set to     0.343416\n",
       "149475  the first     0.337250\n",
       "151294   the pope     0.329685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicwords = basicvectorizer.get_feature_names()\n",
    "basiccoeffs = basicmodel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>if he</td>\n",
       "      <td>-0.330328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30479</th>\n",
       "      <td>in gaza</td>\n",
       "      <td>-0.353752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192198</th>\n",
       "      <td>with iran</td>\n",
       "      <td>-0.367594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10093</th>\n",
       "      <td>bin laden</td>\n",
       "      <td>-0.390027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148766</th>\n",
       "      <td>the country</td>\n",
       "      <td>-0.412813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Coefficient\n",
       "29642         if he    -0.330328\n",
       "30479       in gaza    -0.353752\n",
       "192198    with iran    -0.367594\n",
       "10093     bin laden    -0.390027\n",
       "148766  the country    -0.412813"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (Best Model)  CountVectorizer(two and three connected words) + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5793650793650794\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = CountVectorizer(ngram_range = (2,3), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = LogisticRegression()\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160852</th>\n",
       "      <td>right to</td>\n",
       "      <td>0.296239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170796</th>\n",
       "      <td>set to</td>\n",
       "      <td>0.291049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>and other</td>\n",
       "      <td>0.285157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179603</th>\n",
       "      <td>the first</td>\n",
       "      <td>0.280615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45219</th>\n",
       "      <td>in south</td>\n",
       "      <td>0.268066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Coefficient\n",
       "160852   right to     0.296239\n",
       "170796     set to     0.291049\n",
       "7012    and other     0.285157\n",
       "179603  the first     0.280615\n",
       "45219    in south     0.268066"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicwords = basicvectorizer.get_feature_names()\n",
    "basiccoeffs = basicmodel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191551</th>\n",
       "      <td>up in</td>\n",
       "      <td>-0.240302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>there is</td>\n",
       "      <td>-0.245284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186761</th>\n",
       "      <td>to kill</td>\n",
       "      <td>-0.248780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197466</th>\n",
       "      <td>with iran</td>\n",
       "      <td>-0.251981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178908</th>\n",
       "      <td>the country</td>\n",
       "      <td>-0.350941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Coefficient\n",
       "191551        up in    -0.240302\n",
       "183528     there is    -0.245284\n",
       "186761      to kill    -0.248780\n",
       "197466    with iran    -0.251981\n",
       "178908  the country    -0.350941"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: pd.groupby() is deprecated and will be removed; Please use the Series.groupby() or DataFrame.groupby() methods\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act</th>\n",
       "      <th>pre</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "act pre     \n",
       "0   0    136\n",
       "    1     50\n",
       "1   0    109\n",
       "    1     83"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pd.groupby(pd.DataFrame({'act': test['Label'], 'pre': predictions}),['act','pre']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CountVectorizer(one or two connected words) + Naive Bayes(alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"countvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"countvectorizer__analyzer\": ['char', 'char_wb', 'word'],\n",
    "              \"multinomialnb__alpha\": [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(CountVectorizer(max_features = 200000), MultinomialNB(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, train['Label'])\n",
    "grid.best_params_\n",
    "\n",
    "# results: \n",
    "# {'countvectorizer__analyzer': 'word',\n",
    "#  'countvectorizer__ngram_range': (1, 2),\n",
    "#  'multinomialnb__alpha': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5105820105820106\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = TfidfVectorizer(ngram_range = (1,2), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = MultinomialNB(alpha = 1)\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144244</th>\n",
       "      <td>the</td>\n",
       "      <td>-7.692195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155473</th>\n",
       "      <td>to</td>\n",
       "      <td>-7.901651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67515</th>\n",
       "      <td>of</td>\n",
       "      <td>-8.034307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>in</td>\n",
       "      <td>-8.034625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>and</td>\n",
       "      <td>-8.608300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Coefficient\n",
       "144244  the    -7.692195\n",
       "155473   to    -7.901651\n",
       "67515    of    -8.034307\n",
       "38333    in    -8.034625\n",
       "5191    and    -8.608300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicwords = basicvectorizer.get_feature_names()\n",
    "basiccoeffs = basicmodel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>zumas</td>\n",
       "      <td>-12.300006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>zumas trademark</td>\n",
       "      <td>-12.300006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>zurich will</td>\n",
       "      <td>-12.300006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>zuyevo</td>\n",
       "      <td>-12.300006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>zuyevo rice</td>\n",
       "      <td>-12.300006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word  Coefficient\n",
       "199990            zumas   -12.300006\n",
       "199991  zumas trademark   -12.300006\n",
       "199995      zurich will   -12.300006\n",
       "199996           zuyevo   -12.300006\n",
       "199997      zuyevo rice   -12.300006"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TfidfVectorizer(one or two connected words) + Naive Bayes(alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {#\"tfidfvectorizer__min_df\": np.arange(0, 0.5, 0.01),\n",
    "              #\"tfidfvectorizer__max_df\": np.arange(0.5, 1, 0.01),\n",
    "              \"tfidfvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"tfidfvectorizer__analyzer\": ['char', 'word'],\n",
    "              \"multinomialnb__alpha\": [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(TfidfVectorizer(max_features = 200000), MultinomialNB(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, train['Label'])\n",
    "grid.best_params_\n",
    "\n",
    "# results: \n",
    "# {'multinomialnb__alpha': 0.1,\n",
    "#  'tfidfvectorizer__analyzer': 'word',\n",
    "#  'tfidfvectorizer__ngram_range': (1, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4947089947089947\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = TfidfVectorizer(ngram_range = (1,2), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = MultinomialNB(alpha = 0.1)\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144244</th>\n",
       "      <td>the</td>\n",
       "      <td>-5.990242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155473</th>\n",
       "      <td>to</td>\n",
       "      <td>-6.201811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67515</th>\n",
       "      <td>of</td>\n",
       "      <td>-6.336056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>in</td>\n",
       "      <td>-6.336378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>and</td>\n",
       "      <td>-6.920023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Coefficient\n",
       "144244  the    -5.990242\n",
       "155473   to    -6.201811\n",
       "67515    of    -6.336056\n",
       "38333    in    -6.336378\n",
       "5191    and    -6.920023"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basicwords = basicvectorizer.get_feature_names()\n",
    "basiccoeffs = basicmodel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "coeffdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>zumas</td>\n",
       "      <td>-12.891621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>zumas trademark</td>\n",
       "      <td>-12.891621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>zurich will</td>\n",
       "      <td>-12.891621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>zuyevo</td>\n",
       "      <td>-12.891621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>zuyevo rice</td>\n",
       "      <td>-12.891621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word  Coefficient\n",
       "199990            zumas   -12.891621\n",
       "199991  zumas trademark   -12.891621\n",
       "199995      zurich will   -12.891621\n",
       "199996           zuyevo   -12.891621\n",
       "199997      zuyevo rice   -12.891621"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CountVectorizer(single words) + Random Forest(n_estimators = 200, max_depth = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"countvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"countvectorizer__analyzer\": ['char', 'char_wb', 'word'],\n",
    "              \"randomforestclassifier__n_estimators\": [200, 500, 700],\n",
    "              \"randomforestclassifier__max_features\": ['auto', 'sqrt', 'log2'],\n",
    "              \"randomforestclassifier__max_depth\": [4, 5, 6, 7, 8]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(CountVectorizer(max_features = 200000), RandomForestClassifier(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, train['Label'])\n",
    "grid.best_params_\n",
    "\n",
    "# results:\n",
    "# {'countvectorizer__analyzer': 'char',\n",
    "#  'countvectorizer__ngram_range': (1, 1),\n",
    "#  'randomforestclassifier__max_depth': 8,\n",
    "#  'randomforestclassifier__max_features': 'auto',\n",
    "#  'randomforestclassifier__n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49206349206349204\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = CountVectorizer(ngram_range = (1, 1), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = RandomForestClassifier(n_estimators = 200, max_depth = 8, max_features = 'auto')\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TfidfVectorizer(single words) + Random Forest(n_estimators = 700, max_depth = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"tfidfvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"tfidfvectorizer__analyzer\": ['char', 'word'],\n",
    "              \"randomforestclassifier__n_estimators\": [200, 500, 700],\n",
    "              \"randomforestclassifier__max_features\": ['auto', 'sqrt', 'log2'],\n",
    "              \"randomforestclassifier__max_depth\": [4, 5, 6, 7, 8]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(TfidfVectorizer(max_features = 200000), RandomForestClassifier(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, train['Label'])\n",
    "grid.best_params_\n",
    "\n",
    "# results:\n",
    "# {'randomforestclassifier__max_depth': 5,\n",
    "#  'randomforestclassifier__max_features': 'auto',\n",
    "#  'randomforestclassifier__n_estimators': 700,\n",
    "#  'tfidfvectorizer__analyzer': 'char',\n",
    "#  'tfidfvectorizer__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49206349206349204\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = TfidfVectorizer(ngram_range = (1, 1), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = RandomForestClassifier(n_estimators = 700, max_depth = 5)\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CountVectorizer(one or two connected words) + Neural Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(array):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(array)\n",
    "    coded_array = encoder.transform(array)\n",
    "    n = len(coded_array)\n",
    "    n_labels = len(np.unique(coded_array))\n",
    "    one_hot = np.zeros((n,n_labels))\n",
    "    one_hot[np.arange(n), coded_array] = 1\n",
    "    return one_hot\n",
    "param_grid = {\"countvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"countvectorizer__analyzer\": ['char', 'char_wb', 'word'],\n",
    "              \"mlpclassifier__learning_rate\": ['constant', 'invscaling', 'adaptive'],\n",
    "              \"mlpclassifier__solver\": ['sgd', 'lbfgs', 'adam'],\n",
    "              \"mlpclassifier__activation\": ['logistic', 'tanh', 'relu'],\n",
    "              \"mlpclassifier__hidden_layer_sizes\": [(30,), (60,), (80,)],\n",
    "              \"mlpclassifier__max_iter\": [500, 1000]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(CountVectorizer(max_features = 200000), MLPClassifier(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, one_hot_encoder(train['Label']))\n",
    "grid.best_params_\n",
    "\n",
    "# result:\n",
    "# {\"countvectorizer__analyzer\": 'word',\n",
    "#  \"countvectorizer__ngram_range\": (1, 2),\n",
    "#  \"mlpclassifier__activation\": 'logistic',\n",
    "#  \"mlpclassifier__hidden_layer_sizes\": (60,)\n",
    "#  \"mlpclassifier__learning_rate\": 'adaptive',\n",
    "#  \"mlpclassifier__max_iter\": 500,\n",
    "#  \"mlpclassifier__solver\": 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4973544973544973\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = CountVectorizer(ngram_range = (1, 2), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = MLPClassifier(solver='lbfgs', activation = 'logistic', hidden_layer_sizes=(60,), max_iter = 500, learning_rate = 'adaptive')\n",
    "basicmodel = basicmodel.fit(basictrain, one_hot_encoder(train[\"Label\"]))\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. TfidfVectorizer(two and three connected words) + Neural Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(array):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(array)\n",
    "    coded_array = encoder.transform(array)\n",
    "    n = len(coded_array)\n",
    "    n_labels = len(np.unique(coded_array))\n",
    "    one_hot = np.zeros((n,n_labels))\n",
    "    one_hot[np.arange(n), coded_array] = 1\n",
    "    return one_hot\n",
    "param_grid = {\"countvectorizer__ngram_range\": [(1,1), (1,2), (1,3), (2,2), (2,3)],\n",
    "              \"countvectorizer__analyzer\": ['char', 'char_wb', 'word'],\n",
    "              \"mlpclassifier__learning_rate\": ['constant', 'invscaling', 'adaptive'],\n",
    "              \"mlpclassifier__solver\": ['sgd', 'lbfgs', 'adam'],\n",
    "              \"mlpclassifier__activation\": ['logistic', 'tanh', 'relu'],\n",
    "              \"mlpclassifier__hidden_layer_sizes\": [(30,), (60,), (80,)],\n",
    "              \"mlpclassifier__max_iter\": [500, 1000]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(CountVectorizer(max_features = 200000), MLPClassifier(),\n",
    "                                  memory=\"cache_folder\"),\n",
    "                    param_grid=param_grid, cv=5, scoring = 'accuracy'\n",
    "                   )\n",
    "grid.fit(trainheadlines, one_hot_encoder(train['Label']))\n",
    "grid.best_params_\n",
    "\n",
    "# result:\n",
    "# {\"countvectorizer__analyzer\": 'word',\n",
    "#  \"countvectorizer__ngram_range\": (2, 3),\n",
    "#  \"mlpclassifier__activation\": 'relu',\n",
    "#  \"mlpclassifier__hidden_layer_sizes\": (30,)\n",
    "#  \"mlpclassifier__learning_rate\": 'constant',\n",
    "#  \"mlpclassifier__max_iter\": 500,\n",
    "#  \"mlpclassifier__solver\": 'lbfgs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5608465608465608\n"
     ]
    }
   ],
   "source": [
    "basicvectorizer = TfidfVectorizer(ngram_range = (2, 3), max_features = 200000)\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines)\n",
    "basicmodel = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(30,), max_iter = 500)\n",
    "basicmodel = basicmodel.fit(basictrain, one_hot_encoder(train[\"Label\"]))\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "predictions = np.where(basicmodel.predict_proba(basictest)[:,1] > THRESHOLD, 1, 0)\n",
    "print(accuracy_score(test['Label'], predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
